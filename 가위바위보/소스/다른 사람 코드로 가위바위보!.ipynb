{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고 사이트\n",
    "https://github.com/ljh415/AIFFEL/blob/master/Exploration/01.rock_scissors_paper/rock_scissor_paper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel/anaconda3/lib/python3.7/site-packages (7.0.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# 패키지 설치\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/h_train/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/h_train/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/h_train/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 이미지 리사이징\n",
    "\n",
    "# 가위 이미지 리사이즈\n",
    "\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/h_train/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 바위 이미지 리사이즈\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/h_train/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# ============================================================\n",
    "# 보 이미지 리사이즈\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/h_train/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (2700, 28, 28, 3)\n",
      "y_train shape: (2700,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 및 라벨링\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=2700   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/h_train\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUgklEQVR4nO3dXYyc5XUH8P9/PvbD9prYJgbbGBuooxRFjWlXFiqooooaEd9AVCWKLyIqoToXQUqkXBTRi3CJqiZRLtKoTkFxqpQoUoLgArVBKBKK0kYsyDUmbmJMHWJ7YwO28X7YOzszpxc7VIvZ95zJPDPzTnj+P8na3Tn7vO8z4zkzu3ve8zw0M4jIB1+l7AmIyHAo2UUyoWQXyYSSXSQTSnaRTNSGebLJiQnbOLW+ME7SHe/Fo7GIju2PBum8LkaDI+HcosfFH50k+XHzviPlfnVz9mJRFardbvvjEVWxgrk554/m5oUvXbqEhcWFNU+elOwk7wXwTQBVAP9iZo95379xaj0O/PX+wnitWnfPV68Xx70YAFSr1bR4faznsRHW/PG1avG5AaBSKX4hCl8EK368UvGfIt65AaBe6/1xi+LRub18bTQa7tilpSU33mw23Xj0Q3Or1SqMLS8vu2PbxUPxrX/+px5n5CBZBfAtAJ8CcDuAAyRv7/V4IjJYKb+z7wPwmpm9bmYNAD8AcF9/piUi/ZaS7DsA/HbV16c7t70HyYMkZ0jOXLnq/2gkIoOTkuxr/bL3vj8dmNkhM5s2s+nJifGE04lIipRkPw1g56qvbwJwNm06IjIoKcn+IoA9JG8hOQbgcwCe6c+0RKTfei69mVmT5EMA/gMrpbcnzOxVdxCJCovLKVEpJaXElHLsKB6XgPyaLcwfH9ddEzoXS2x6TO24TKlHD1r0f+6V3qKx0dOpSFKd3cyeBfBsyjFEZDh0uaxIJpTsIplQsotkQskukgklu0gmlOwimRhqPztJtxW1VvOnMzZW3C4ZjY3ilajNNKFVM6rDM2jtTWkFtajDNbGFNYzXiu9bNDa639G1FV49ulL373fUdtxc9ovdUQts1amzV6IWV+fUdFqW9c4ukgklu0gmlOwimVCyi2RCyS6SCSW7SCaGWnqrkJiYmCiMD7L0Vg1KLV5pLTp+WHoLjh2Nj+4bq17rb1r5KrX0xmrx3ONzB/c7LL0V16ii0lj0mLeafv+s18Ianb/Z7L09tlJxWsjdo4rIB4aSXSQTSnaRTCjZRTKhZBfJhJJdJBNKdpFM/EG1uLpjx/w20ZQ6ehSP2iErDK4BSNzNNKWWHcVT23db7jLZadtJD3KJbSK6334tPH7cveP7La69Lqmud3aRTCjZRTKhZBfJhJJdJBNKdpFMKNlFMqFkF8nE0OvsXt027gv3xkZ19sSlpp1++GplcEtBA0C17l8jkLKVdRRH6lLSTp09PHci7/hhHZ1+HT2u4QfXH7g96b1vAV5x7nNSspM8BWAOQAtA08ymU44nIoPTj3f2vzSzt/pwHBEZIP3OLpKJ1GQ3AD8h+RLJg2t9A8mDJGdIziwsLiaeTkR6lfpj/F1mdpbkVgDPkfwfM3th9TeY2SEAhwDgpu039t6ZICJJkt7Zzexs5+N5AE8B2NePSYlI//Wc7CTXk5x693MAnwRwrF8TE5H+Svkx/gYAT3VqmTUA/2Zm/+4NICuojw9m3Xiv172beLSFb702XhiL6uThuZ1tjbs5vleXtbDOPthtkxGsW58i7mcvnptXq049djfH9+rs0R4H3pr1dJ4LPSe7mb0O4OO9jheR4VLpTSQTSnaRTCjZRTKhZBfJhJJdJBNDb3FN2XY5pfRWjZaarvptpN7xo/IUnG10gbilMT5+8fhKUFob+JbNwbbLnqi8lbKUdDTv6NyRaEtod27B0uNWKS7baSlpEVGyi+RCyS6SCSW7SCaU7CKZULKLZELJLpKJodbZQb++GbZyess514tbUAGg5mxrDMR1eu8agKhFNbp+wGt37Ob44+PF9z1qtQyX0A7q0Y1Gw417WxOnLnOdshR1aotqVOOPnsvedR3LFX/LZm9uqrOLiJJdJBdKdpFMKNlFMqFkF8mEkl0kE0p2kUwMt84Ogs7Wyl4M8LdGDuuaQT053i6693OH/erBlszRNQBubTXa/hfBJj1BPXpsfNIf7oxP3bI5Gu+dO95y2ReNj3rSYcX97tGxWy3V2UXEoWQXyYSSXSQTSnaRTCjZRTKhZBfJhJJdJBNDXzfeqxlHtXAvnjIWiGvd3viozm7B2u2Tk36tOqqVt6y47lpzrk0A4l76iNdLDwDNtrO9cGKdHRat/V587qhfHQk1/JXhwX2rONcARH381QHV2Uk+QfI8yWOrbttM8jmSJzofN0XHEZFydfNj/HcB3HvNbQ8DeN7M9gB4vvO1iIywMNnN7AUAF665+T4AhzufHwZwf3+nJSL91usf6G4ws1kA6HzcWvSNJA+SnCE5Mz+/0OPpRCTVwP8ab2aHzGzazKY3bFg/6NOJSIFek/0cyW0A0Pl4vn9TEpFB6DXZnwHwQOfzBwA83Z/piMighHV2kk8CuAfA9SRPA/gqgMcA/JDkgwDeAPCZbk5G0q1Jp/ScV5015YF47fWoVu7FGYwl/LppdL9DVnz+qA4e1dmjfcbDdeeduQ2aV2eP7ndUho/q9NG1EXCeE1Grfa/rxofPMjM7UBD6RDRWREaHLpcVyYSSXSQTSnaRTCjZRTKhZBfJxJCXkvZLEuEWvVVvbNpyzmGpxIlXKmnlpai8VQmW2Ha3k06831FJMlqKOhrviZeK9s/txaPnS7iNdlha83kPS9h+2yO9s4tkQskukgklu0gmlOwimVCyi2RCyS6SCSW7SCaGvpS0WyuvBu2SlcHVk+N4cWE0Ghu1gS63/Dr7urGJno9/5coVf+yYX8OfnPRXF1peXnbjKctFh9ddJC33nFbLjmvh0dyKY+G1Ce4S2tqyWSR7SnaRTCjZRTKhZBfJhJJdJBNKdpFMKNlFMlFCP3vvWx+7S0kHY1P61aPjR8ceG/O3g16a9+vs0Xjv/G9fvHabvveK6uhTU9e58aje3HL63eM6uhsOed3u5myZvDI2OnmwfHg0ea/QHjyf6GRt0pbNIvLBoGQXyYSSXSQTSnaRTCjZRTKhZBfJhJJdJBND72f3asJRvdqtIQ64nz3l3FGdHFh0o/W633Pu1brfeecdd2yzmbb1cHR9Qys4foqUfvdozfmwTh6EUx63pHXjnXmF7+wknyB5nuSxVbc9SvIMySOdf/t7n52IDEM3P8Z/F8C9a9z+DTPb2/n3bH+nJSL9Fia7mb0AwL/mUkRGXsof6B4iebTzY/6mom8ieZDkDMmZy3NzCacTkRS9Jvu3AdwGYC+AWQBfK/pGMztkZtNmNr1xaqrH04lIqp6S3czOmVnLzNoAvgNgX3+nJSL91lOyk9y26stPAzhW9L0iMhrCOjvJJwHcA+B6kqcBfBXAPST3YqVl+BSAL3Rzsmq7jQ9dLa4pm61zx7dqk4WxBfp92a26f+z2uP9Q1GvFBczJit+Pbk3/bxUf2eX3jJ87cdQfv/3mwtiZc6fdsX/28TvdeO3MJTd+9NhxN/729sI/52D79u3u2C1btrjxaA/1paWlwljUr07674Nt88/davl1/La3vnvNv66C7r7zxccNk93MDqxx8+PROBEZLbpcViQTSnaRTCjZRTKhZBfJhJJdJBPDXUqaAJ3WPi8GAOa0DVad0hgAWNWPV4Jz153xYwxKQItX3fjs4mU3fvP2HW7c2zZ5bmHeHfvWBb/t4fybp9x4s+2XmHbt2lUY27Bhgzs2ahNtNBpu3BO1DUfnjsp+jYZfji2D3tlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXyYSSXSQTQ62zG4imU78MugoBZ5td+uVeVILVeSst/xu8Mn0lOPlNN2xz48sXz7nxaLnn35z838LYmbOz7thNm/z4jpv+yI3fcuseN/7GeO9LcEd19CjutXtGS0VHS003m34dPVzmOuHcvdI7u0gmlOwimVCyi2RCyS6SCSW7SCaU7CKZULKLZGLIdXagAWcZ3OgAbaeHuBX0DzeLe74BgEGtvOqUuivBUtKnfnXCjd94nb/M9VsX/G2XWS3uzd55y63u2Kvm1/A337jVjZ+7+LYbX9xYfN+i7Z4j0XgvHtXBvTUCgLjGX6sF23SHT/b+0zu7SCaU7CKZULKLZELJLpIJJbtIJpTsIplQsotkYrh1dgJLTk96JSg+1pwafTVYv7zS9uumtWCL3TErrtnW6dfZd+/2a93vzJ5x4//58/9y46+dKK7jE/766B/92J+4cUz69eJasNW1t7561M8ere0e1co9raBnPDp2rZaWOik9695Y77DhOzvJnSR/SvI4yVdJfqlz+2aSz5E80flYvBG3iJSumx/jmwC+YmZ/DOBOAF8keTuAhwE8b2Z7ADzf+VpERlSY7GY2a2Yvdz6fA3AcwA4A9wE43Pm2wwDuH9AcRaQPfq8/0JHcDeAOAL8AcIOZzQIrLwgA1ryImuRBkjMkZy7P+fuOicjgdJ3sJDcA+BGAL5uZvxPhKmZ2yMymzWx645S/kZ+IDE5XyU6yjpVE/76Z/bhz8zmS2zrxbQDOD2aKItIPYf2AKzWIxwEcN7Ovrwo9A+ABAI91Pj4dHcsANJ22w2qwrXLVK9tFLapBqWMsKL2NW3F5bSw49/Lcoht//dd+CyzNf02uOu2UW7fvdMfevnevG5+9+JYbr4z5pbn6+g8VxlJbXKNtk73lnqOtpqOyYDT35WV/bm2njByV5fx4caybYuFdAD4P4BWSRzq3PYKVJP8hyQcBvAHgM10cS0RKEia7mf0Mxa32n+jvdERkUHS5rEgmlOwimVCyi2RCyS6SCSW7SCaG2uLaJrHk7Mtcd2qEAFDz6ottv800qujWg/EVp+WxGrxkvnnaX275UrBU9Pj4pBvfd+fdhbHtu3e5Y2/+iL8l8+zbF914ve4/st6VEyl1ciCuR3vHj+rsUYtrVIePOlgtoc7ebgf7jxfQO7tIJpTsIplQsotkQskukgklu0gmlOwimVCyi2RiuEtJG7Dk1sr9+mLdqbu2zK+LMthWuRK87lWdumr0inn54gU3PjE24cbP/G7WjX907x2Fsc3btrljz1306+iVCb9ffRl+zbfq1LqjenJUy46Wc/aWom4002r80TUC0bMipc7e6zLUemcXyYSSXSQTSnaRTCjZRTKhZBfJhJJdJBNKdpFMDLef3QxXG8V12eq4P37Z2Xb5urpfD640/S2bmw0/Dqdm+7s3/bXVT5486cYvz/vryu+7+8/d+M7dtxXGLi35x14M7nczeNzGJvz/tDEU16OjnvGob7vRaLhxT7BNQHjuqNa9bp2/BoG3bnx0bq/G7z2memcXyYSSXSQTSnaRTCjZRTKhZBfJhJJdJBNKdpFMdLM/+04A3wNwI4A2gENm9k2SjwL4WwBvdr71ETN7Njpeq11cB4yWw26b0xu9HNSLry74x77q12wXnd7q+UuX3LGNq0tufMuHt7rxjZs/7MYXlorv+3xwv9rBy32z7fdtM4hXnf+zSFSHj+KeaN341J7yqN/dq7OHY51E8abVzUU1TQBfMbOXSU4BeInkc53YN8zsH7s4hoiUrJv92WcBzHY+nyN5HMCOQU9MRPrr9/qdneRuAHcA+EXnpodIHiX5BMlNBWMOkpwhObMwN582WxHpWdfJTnIDgB8B+LKZXQbwbQC3AdiLlXf+r601zswOmdm0mU2vn9qQPmMR6UlXyU6yjpVE/76Z/RgAzOycmbXMrA3gOwD2DW6aIpIqTHau/MnzcQDHzezrq25fvWzppwEc6//0RKRfuvlr/F0APg/gFZJHOrc9AuAAyb0ADMApAF+IDmQGNJvFZYNmxa+9ta14ed8mr7pjW4t+q2d7fs6NLzkljQsX/BbXpWW//HXrju1ufOP1W9z45SvF931+yS/7cdzfcnk5KGlW6v77RTPYCtvzh1x6i5aiHlTpDc5xu/lr/M+w9jbbYU1dREaHrqATyYSSXSQTSnaRTCjZRTKhZBfJhJJdJBNDXUoaBljTeX2p+rXLttNO2a74Y9m44saXghZYtoprm/MLl92xLfqvqVObNrvx6vg6N764UDz3dnDuavB6vxTU6SfX+UtJ97rscT/iXi08KLMnLyUdLgdtxfForN/iWjwvvbOLZELJLpIJJbtIJpTsIplQsotkQskukgklu0gmGNUL+3oy8k0Av1l10/UA/Gbw8ozq3EZ1XoDm1qt+zm2Xma259vhQk/19JydnzGy6tAk4RnVuozovQHPr1bDmph/jRTKhZBfJRNnJfqjk83tGdW6jOi9Ac+vVUOZW6u/sIjI8Zb+zi8iQKNlFMlFKspO8l+SvSL5G8uEy5lCE5CmSr5A8QnKm5Lk8QfI8yWOrbttM8jmSJzof19xjr6S5PUryTOexO0Jyf0lz20nypySPk3yV5Jc6t5f62DnzGsrjNvTf2UlWAfwawF8BOA3gRQAHzOyXQ51IAZKnAEybWekXYJD8CwDzAL5nZh/r3PYPAC6Y2WOdF8pNZvZ3IzK3RwHMl72Nd2e3om2rtxkHcD+Av0GJj50zr89iCI9bGe/s+wC8Zmavm1kDwA8A3FfCPEaemb0A4MI1N98H4HDn88NYebIMXcHcRoKZzZrZy53P5wC8u814qY+dM6+hKCPZdwD47aqvT2O09ns3AD8h+RLJg2VPZg03mNkssPLkAbC15PlcK9zGe5iu2WZ8ZB67XrY/T1VGsq+1cNgo1f/uMrM/BfApAF/s/Lgq3elqG+9hWWOb8ZHQ6/bnqcpI9tMAdq76+iYAZ0uYx5rM7Gzn43kAT2H0tqI+9+4Oup2P50uez/8bpW2819pmHCPw2JW5/XkZyf4igD0kbyE5BuBzAJ4pYR7vQ3J95w8nILkewCcxeltRPwPggc7nDwB4usS5vMeobONdtM04Sn7sSt/+3MyG/g/Afqz8Rf4kgL8vYw4F87oVwH93/r1a9twAPImVH+uWsfIT0YMAtgB4HsCJzsfNIzS3fwXwCoCjWEmsbSXN7W6s/Gp4FMCRzr/9ZT92zryG8rjpclmRTOgKOpFMKNlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXycT/Abf4pwP9bBPIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 맞는 지 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rcp_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 28, 28, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 422,218\n",
      "Trainable params: 422,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 네트워크 설계\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "\n",
    "inputs = layers.Input((28, 28, 3), name = 'input_layer')\n",
    "\n",
    "# Feature Extraction\n",
    "net = layers.Conv2D(32, (3, 3), padding = 'SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D((2, 2))(net)\n",
    "net = layers.Dropout(0.5)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding = 'SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D((2, 2))(net)\n",
    "net = layers.Dropout(0.5)(net)\n",
    "\n",
    "# Classification\n",
    "net = layers.Flatten()(net)  \n",
    "net = layers.Dense(128)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(0.4)(net)\n",
    "net = layers.Dense(10)(net)  \n",
    "\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs=net, name='rcp_CNN')\n",
    "# estimator = tf.keras.estimator.model_to_estimator(model)\n",
    "# 위에 처럼 만든 모델을 에스티메이터로 바꾸고 싶을때는 이렇게\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 1.1848 - accuracy: 0.3515\n",
      "Epoch 2/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 1.0849 - accuracy: 0.4056\n",
      "Epoch 3/30\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.9805 - accuracy: 0.5107\n",
      "Epoch 4/30\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.8527 - accuracy: 0.6081\n",
      "Epoch 5/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.6681\n",
      "Epoch 6/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.7181\n",
      "Epoch 7/30\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.5819 - accuracy: 0.7515\n",
      "Epoch 8/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7930\n",
      "Epoch 9/30\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.8226\n",
      "Epoch 10/30\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8393\n",
      "Epoch 11/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8737\n",
      "Epoch 12/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.8796\n",
      "Epoch 13/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8844\n",
      "Epoch 14/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.8930\n",
      "Epoch 15/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2377 - accuracy: 0.9074\n",
      "Epoch 16/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2291 - accuracy: 0.9156\n",
      "Epoch 17/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9233\n",
      "Epoch 18/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.2035 - accuracy: 0.9241\n",
      "Epoch 19/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9300\n",
      "Epoch 20/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9263\n",
      "Epoch 21/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9348\n",
      "Epoch 22/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9381\n",
      "Epoch 23/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9441\n",
      "Epoch 24/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9511\n",
      "Epoch 25/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9507\n",
      "Epoch 26/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9522\n",
      "Epoch 27/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9556\n",
      "Epoch 28/30\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9493\n",
      "Epoch 29/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9615\n",
      "Epoch 30/30\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f927a5f8a90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딥러닝 네트워크 학습\n",
    "\n",
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "\n",
    "# 채널 수에 대한 정보 (RGB=3)\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 test 데이터 만들기\n",
    "\n",
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "def re_load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_test, y_test)= re_load_data(image_dir_path)\n",
    "x_test_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 782.7782 - accuracy: 0.3667\n",
      "test_loss: 782.7781982421875 \n",
      "test_accuracy: 0.36666667461395264\n"
     ]
    }
   ],
   "source": [
    "# 모델평가\n",
    "\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
